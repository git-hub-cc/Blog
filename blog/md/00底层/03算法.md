### **第一章：按设计范式/策略分类 (Classification by Design Paradigm)**

设计范式是解决问题的通用方法论。掌握这些范式，可以帮助我们为不同类型的问题设计出高效的算法。

#### **1.1 暴力法 (Brute-force / Exhaustive Search)**

*   **1.1.1 暴力/穷举搜索 (Brute-force Search):**
    最直接的解决方式。它会尝试每一种可能的解决方案，直到找到符合条件的解。虽然通常效率低下，但思路简单，是解决问题的起点，也常作为衡量其他算法性能的基准。

#### **1.2 分治法 (Divide and Conquer)**

将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。通常涉及三个步骤：分解（Divide）、解决（Conquer）、合并（Combine）。

*   **1.2.1 归并排序 (Merge Sort):**
    将数组递归地对半拆分，直到每个子数组只有一个元素，然后逐层将已排序的子数组合并起来。这是一种稳定且高效的排序算法，时间复杂度为O(n log n)。

*   **1.2.2 快速排序 (Quicksort):**
    通过一个“基准”元素将数组分区，再对两个子分区递归地应用此过程。它是一种高效但不稳定的分治排序算法，平均时间复杂度为O(n log n)。

*   **1.2.3 二分搜索 (Binary Search):**
    在有序数组中查找元素。每次都检查数组的中间元素，如果目标值与中间元素不符，则根据大小关系在左半部分或右半部分继续查找，每次都将搜索范围减半。

*   **1.2.4 大整数乘法 (Karatsuba Algorithm):**
    一种比传统竖式乘法更快的整数乘法算法。它将大整数分成较小的部分，通过巧妙的代数运算减少了乘法操作的次数，是分治法的经典应用。

*   **1.2.5 寻找最近点对 (Closest Pair of Points Problem):**
    在二维平面上寻找距离最近的两个点。通过分治法，将点集按x坐标分成两半，递归地找到左右两边的最近点对，再处理跨越中间区域的点对。

*   **1.2.6 斯特拉森矩阵乘法 (Strassen's Algorithm):**
    一种比标准矩阵乘法（O(n³))更快的算法。它将矩阵分块，并用7次矩阵乘法和18次加减法代替了标准的8次乘法和4次加法，降低了时间复杂度。

*   **1.2.7 快速傅里叶变换 (Fast Fourier Transform - FFT):**
    高效计算离散傅里叶变换（DFT）及其逆变换的算法。通过分治策略，将DFT的计算复杂度从O(n²)降低到O(n log n)，在信号处理和工程领域应用广泛。

#### **1.3 动态规划 (Dynamic Programming - DP)**

通过将原问题分解为相互重叠的子问题，并存储已解决子问题的结果，以避免重复计算。它适用于具有最优子结构和重叠子问题特性的问题，是解决优化问题的强大工具。

*   **1.3.1 斐波那契数列 (Fibonacci Sequence with Memoization):**
    计算斐波那契数列时，将已计算过的f(n)值存储起来（通常用数组或哈希表），再次需要时直接查询而非重新计算，显著提高了效率。

*   **1.3.2 0-1背包问题 (0-1 Knapsack Problem):**
    给定一组物品，每个物品有自己的重量和价值，在限定的总重量内，如何选择装入背包的物品，使得总价值最大。DP通过构建二维表来记录不同重量限制下的最优解。

*   **1.3.3 最长公共子序列 (Longest Common Subsequence - LCS):**
    寻找两个（或多个）已知序列的最长子序列，这个子序列在所有已知序列中都以相同的相对顺序出现，但不必是连续的。DP是解决此问题的标准方法。

*   **1.3.4 最长递增子序列 (Longest Increasing Subsequence - LIS):**
    在一个给定的数值序列中，找到一个最长的子序列，要求这个子序列中的所有元素都是单调递增的。DP可以通过O(n²)或优化后的O(n log n)复杂度解决。

*   **1.3.5 编辑距离 (Edit Distance / Levenshtein Distance):**
    衡量两个字符串之间的差异程度，定义为将一个字符串转换成另一个所需的最少单字符编辑（插入、删除或替换）次数。DP被用来计算这个最小距离。

*   **1.3.6 矩阵链乘法 (Matrix Chain Multiplication):**
    给定一个矩阵链，寻找最优的加括号方式，使得执行乘法所需的标量乘法次数最少。DP用于确定最佳的计算顺序，而非执行乘法本身。

*   **1.3.7 Floyd-Warshall算法 (Floyd-Warshall Algorithm):**
    解决图中任意两个顶点之间的最短路径问题（所有对最短路径）。它是一种DP算法，通过逐步增加中间顶点来更新所有顶点对之间的最短距离。

*   **1.3.8 Viterbi算法 (Viterbi Algorithm):**
    在隐马尔可夫模型（HMM）等模型中，用于寻找最有可能产生观测序列的隐藏状态序列（即“维特比路径”）。它是一种基于DP的解码算法。

*   **1.3.9 贝尔曼-福特算法 (Bellman-Ford Algorithm):**
    计算图中从单一源点到所有其他顶点的最短路径，可以处理带有负权重边的图。其核心思想是对所有边进行|V|-1次松弛操作，是DP思想的体现。

#### **1.4 贪心算法 (Greedy Algorithm)**

在每一步选择中，都采取在当前状态下最好或最优的选择，从而希望导致全局结果是最好或最优的。贪心算法并不从整体最优上加以考虑，所作出的仅是在某种意义上的局部最优解。

*   **1.4.1 活动选择问题 (Activity Selection Problem):**
    给定n个活动及其开始和结束时间，选择一个最大数量的互相兼容的活动集合。贪心策略是每次都选择结束时间最早的那个活动。

*   **1.4.2 霍夫曼编码 (Huffman Coding):**
    一种用于无损数据压缩的贪心算法。它根据字符出现的频率，为高频字符分配较短的编码，为低频字符分配较长的编码，从而得到最优的前缀码。

*   **1.4.3 Kruskal算法 (Kruskal's Algorithm):**
    寻找图的最小生成树。它将所有边按权重从小到大排序，然后依次考察每条边，如果这条边连接的两个顶点不在同一个连通分量中，就将其加入最小生成树。

*   **1.4.4 Prim算法 (Prim's Algorithm):**
    同样用于寻找图的最小生成树。它从一个起始顶点开始，逐步扩大树的规模，每次都选择连接树内顶点和树外顶点的所有边中权重最小的那一条。

*   **1.4.5 Dijkstra算法 (Dijkstra's Algorithm):**
    计算图中从单一源点到所有其他顶点的最短路径，适用于所有边权重为非负数的图。它贪心地选择当前已知距离源点最近的未访问顶点进行扩展。

*   **1.4.6 分数背包问题 (Fractional Knapsack Problem):**
    与0-1背包不同，这里的物品可以被分割。贪心策略是优先选择单位重量价值最高的物品装入背包，直到装满为止。

#### **1.5 回溯法 (Backtracking)**

一种通过探索所有可能的候选解来找出所有解的算法。如果发现某个候选解不可能是解（或者不是最优解），就“回溯”（即放弃该解），并尝试其他候选解。它是一种深度优先搜索（DFS）的体现。

*   **1.5.1 N皇后问题 (N-Queens Problem):**
    在N×N的棋盘上放置N个皇后，使得它们不能互相攻击。回溯法逐行放置皇后，若当前位置冲突，则回溯到上一行，尝试新的位置。

*   **1.5.2 子集和问题 (Sum of Subsets Problem):**
    给定一个正整数集合和一个目标值，找出集合中是否存在一个子集，使得子集中所有元素的和等于目标值。回溯法通过构建状态空间树来系统地搜索所有可能的子集。

*   **1.5.3 图着色问题 (Graph Coloring Problem):**
    用k种颜色为图的顶点着色，使得任意两个相邻的顶点颜色都不同。回溯法尝试为每个顶点分配颜色，如果发现冲突，就回溯并尝试另一种颜色。

*   **1.5.4 迷宫求解 (Maze Solving):**
    从迷宫的起点找到通往终点的路径。回溯法从起点开始，沿着一个方向探索，遇到死路就返回到上一个路口，选择另一条路继续探索。

*   **1.5.5 正则表达式匹配 (Regular Expression Matching):**
    实现一个支持'.'和'*'的正则表达式匹配。回溯法可以用来探索所有可能的匹配路径，当遇到'*'时，它可以匹配零个、一个或多个前面的元素。

#### **1.6 分支限界法 (Branch and Bound)**

与回溯法类似，也是一种在问题的解空间树上搜索问题解的算法。但它通常用于求解最优化问题，通过界定函数（Bounding Function）来“剪枝”，提前排除那些不可能包含最优解的子树。

*   **1.6.1 旅行商问题 (Traveling Salesperson Problem - TSP):**
    寻找访问n个城市并返回起点的最短路径。分支限界法通过计算部分路径的成本下界，来剪掉那些成本已经超过当前已知最优解的搜索分支。

*   **1.6.2 0-1背包问题的分支限界解法:**
    与DP解法不同，分支限界法将物品排序后构建状态空间树。通过计算节点价值的上界，如果上界已小于当前找到的最优解，则该子树被剪掉。

*   **1.6.3 任务分配问题 (Assignment Problem):**
    将n个任务分配给n个工人，每个工人执行每个任务的成本不同，目标是最小化总成本。分支限界法可以系统地搜索所有分配方案，并利用成本下界进行剪枝。

#### **1.7 随机化算法 (Randomized Algorithm)**

算法在执行过程中，利用一个随机数源，做出随机性的选择。其性能或输出（或两者）是输入和随机数共同作用的结果。

*   **1.7.1 蒙特卡洛算法 (Monte Carlo Algorithm):**
    一类随机化算法，其输出结果可能不是精确的，但得到错误结果的概率可以控制。它通常用于求数值近似解，例如用投点法计算圆周率π。

*   **1.7.2 拉斯维加斯算法 (Las Vegas Algorithm):**
    另一类随机化算法，它总能给出正确的结果，但其运行时间是随机的，没有上限。快速排序的随机化版本就是一个典型的拉斯维加斯算法。

*   **1.7.3 Miller-Rabin素性测试 (Miller-Rabin Primality Test):**
    一种高效的随机化素数判定算法。对于一个合数，它有很高的概率（可按需调整）将其识别为合数；对于一个素数，它总能正确判断。

*   **1.7.4 Reservoir Sampling (水塘抽样):**
    用于从一个未知大小的数据流中，随机选择k个样本，且保证每个元素被选中的概率相等。它只需对数据流进行一次遍历即可完成。

#### **1.8 启发式算法 (Heuristic Algorithm)**

为解决一个问题而给出的一种基于经验或直觉的方法，它不能保证找到最优解，但通常能在可接受的时间和空间内找到一个较好的解。

*   **1.8.1 A* 搜索算法 (A* Search Algorithm):**
    一种在图形平面上，有多个节点的路径，求出最低成本路径的启发式搜索算法。它通过估价函数 f(n) = g(n) + h(n) 来指导搜索方向，是Dijkstra算法的扩展。

*   **1.8.2 模拟退火 (Simulated Annealing):**
    源于固体退火原理的随机优化算法。它以一定的概率接受比当前解更差的解，从而有机会跳出局部最优，去寻找全局最优解。

*   **1.8.3 遗传算法 (Genetic Algorithm):**
    模拟自然选择和遗传学机理的生物进化过程的计算模型。通过选择、交叉和变异等操作，在潜在解的群体中逐步演化出更好的解。

*   **1.8.4 蚁群算法 (Ant Colony Optimization):**
    模拟蚂蚁觅食行为的启发式算法。蚂蚁在路径上留下信息素，其他蚂蚁会倾向于选择信息素浓度高的路径，从而形成正反馈，最终找到最优路径。

*   **1.8.5 粒子群优化 (Particle Swarm Optimization - PSO):**
    源于对鸟群捕食行为的研究。每个粒子代表一个潜在解，通过追随自身历史最优位置和群体历史最优位置来更新自己的速度和位置，从而在解空间中搜索。

#### **1.9 近似算法 (Approximation Algorithm)**

用于解决NP-hard优化问题的一种算法。它能在多项式时间内找到一个解，这个解的质量可以被证明与最优解的质量相差在一个可控的因子范围内。

*   **1.9.1 顶点覆盖问题的近似算法 (Vertex Cover Approximation):**
    寻找图中最小的顶点集合，使得图中每条边都至少与集合中的一个顶点相连。一个简单的近似算法是：只要图中还有边，就任选一条边，将其两个端点都加入覆盖集。

*   **1.9.2 旅行商问题的近似算法 (TSP Approximation):**
    对于满足三角不等式的TSP问题，可以通过先求最小生成树，再进行深度优先遍历的方式，得到一个近似比为2的解。

---

### **第二章：按问题领域/应用分类 (Classification by Problem Domain)**

这是更实用的分类方法，直接关联到算法要解决的具体问题。

#### **2.1 排序算法 (Sorting Algorithms)**

将一个元素列表或数组按特定顺序（如数字大小、字典序）进行排列的算法。

*   **2.1.1 冒泡排序 (Bubble Sort):**
    重复地遍历要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。遍历数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。

*   **2.1.2 选择排序 (Selection Sort):**
    每次从未排序的部分中找到最小（或最大）的元素，存放到排序序列的起始位置，然后再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。

*   **2.1.3 插入排序 (Insertion Sort):**
    通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。它在实现上，通常也采用in-place排序。

*   **2.1.4 希尔排序 (Shell Sort):**
    也称缩小增量排序，是插入排序的一种更高效的改进版本。它通过将相距某个“增量”的记录组成一个子序列，然后对每个子序列进行插入排序，最后增量逐渐减为1。

*   **2.1.5 归并排序 (Merge Sort):**
    (见 1.2.1) 将数组递归地对半拆分，直到每个子数组只有一个元素，然后逐层将已排序的子数组合并起来。这是一种稳定且高效的排序算法。

*   **2.1.6 快速排序 (Quicksort):**
    (见 1.2.2) 通过一个“基准”元素将数组分区，再对两个子分区递归地应用此过程。它是一种高效但不稳定的分治排序算法。

*   **2.1.7 堆排序 (Heap Sort):**
    利用堆这种数据结构所设计的一种选择排序。它将待排序序列构造成一个大顶堆（或小顶堆），此时，整个序列的最大值（或最小值）就是堆顶的根节点，然后将其与末尾元素交换。

*   **2.1.8 计数排序 (Counting Sort):**
    一种非比较排序算法，适用于整数排序。它通过统计每个整数出现的次数，然后根据统计结果将元素放回原数组的正确位置。它需要额外的空间来存储计数。

*   **2.1.9 桶排序 (Bucket Sort):**
    计数排序的升级版，适用于数据分布均匀的场景。它将数据分布到有限数量的“桶”里，然后对每个桶内的数据进行排序，最后依次把各个桶中的数据拼接起来。

*   **2.1.10 基数排序 (Radix Sort):**
    一种非比较整数排序算法。它将整数按位数切割成不同的数字，然后按每个位数分别比较。通常从最低位开始，依次对每一位进行排序（如使用计数排序）。

*   **2.1.11 拓扑排序 (Topological Sort):**
    对一个有向无环图（DAG）的所有顶点进行线性排序，使得图中任意一对顶点u和v，若存在边u->v，则u在排序序列中出现在v之前。

*   **2.1.12 外部排序 (External Sort):**
    用于处理无法一次性装入内存的大量数据。它将数据分成可以装入内存的小块，对每块进行内部排序，然后将这些排好序的块进行多路归并。

#### **2.2 搜索算法 (Searching Algorithms)**

用于在数据集合中查找特定元素的算法。

*   **2.2.1 线性搜索 (Linear Search):**
    也叫顺序搜索，是最简单的搜索算法。它逐个检查列表中的每个元素，直到找到目标元素或列表检查完毕。适用于任何类型的列表，无论是否有序。

*   **2.2.2 二分搜索 (Binary Search):**
    (见 1.2.3) 在有序数组中查找元素。每次都检查数组的中间元素，如果目标值与中间元素不符，则根据大小关系在左半部分或右半部分继续查找。

*   **2.2.3 插值搜索 (Interpolation Search):**
    二分搜索的改进版，适用于数值分布均匀的有序数组。它不是每次都取中点，而是根据目标值在整个数据范围内的位置，预测其可能出现的位置进行查找。

*   **2.2.4 跳转搜索 (Jump Search):**
    在有序数组中，不逐个检查元素，而是向前“跳转”一个固定的步长，当目标值位于两个跳转点之间时，再在该小范围内进行线性搜索。

*   **2.2.5 斐波那契搜索 (Fibonacci Search):**
    一种利用斐波那契数作为分割点的搜索算法，适用于有序数组。其分割策略与黄金分割比例有关，是一种高效的搜索方法。

*   **2.2.6 哈希表搜索 (Hash Table Search):**
    通过哈希函数将键（key）映射到哈希表中的一个位置，从而实现近乎常数时间O(1)的查找、插入和删除操作。处理哈希冲突是其关键。

*   **2.2.7 深度优先搜索 (Depth-First Search - DFS):**
    一种用于遍历或搜索树或图的算法。沿着树的深度遍历树的节点，尽可能深地搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现v的那个节点。

*   **2.2.8 广度优先搜索 (Breadth-First Search - BFS):**
    也是一种图搜索算法。从根（或任意节点）开始，探索最靠近根的节点，然后是次近的节点，以此类推。常用于寻找最短路径（在无权图中）。

*   **2.2.9 A* 搜索算法 (A* Search Algorithm):**
    (见 1.8.1) 一种在图形平面上，有多个节点的路径，求出最低成本路径的启发式搜索算法。它结合了Dijkstra算法的优点和启发式搜索的效率。

*   **2.2.10 迭代加深深度优先搜索 (Iterative Deepening DFS - IDDFS):**
    一种结合了DFS的空间优势和BFS的最优性（找到最短路径）的图搜索算法。它通过限制搜索深度，并逐步增加深度限制来进行多次DFS。

*   **2.2.11 双向搜索 (Bidirectional Search):**
    同时从起点和终点开始进行搜索（通常是BFS），当两个搜索相遇时，便找到了路径。在状态空间巨大的情况下，可以显著减少搜索的节点数。

#### **2.3 图算法 (Graph Algorithms)**

图算法是计算机科学的核心，用于解决由顶点（节点）和边（连接）构成的网络结构问题，应用遍及社交网络、地图导航、网络路由等领域。

*   **2.3.1 最短路径算法 (Shortest Path Algorithms)**
    *   **2.3.1.1 Dijkstra算法 (Dijkstra's Algorithm):**
        (见 1.4.5) 用于计算单源最短路径，适用于所有边权重为非负数的图。它是一种基于贪心策略的算法，效率高，应用广泛。
    *   **2.3.1.2 贝尔曼-福特算法 (Bellman-Ford Algorithm):**
        (见 1.3.9) 同样计算单源最短路径，但能处理带负权重边的图，并能检测出图中是否存在负权重环路。
    *   **2.3.1.3 SPFA (Shortest Path Faster Algorithm):**
        贝尔曼-福特算法的队列优化版本。在许多情况下比Bellman-Ford快得多，但其最坏情况时间复杂度与Bellman-Ford相同，在特定构造的图中可能效率不高。
    *   **2.3.1.4 Floyd-Warshall算法 (Floyd-Warshall Algorithm):**
        (见 1.3.7) 解决所有顶点对之间的最短路径问题（APSP）。它使用动态规划，通过考虑所有可能的中间点来逐步更新任意两点间的最短距离。
    *   **2.3.1.5 Johnson算法 (Johnson's Algorithm):**
        一种用于稀疏图中计算所有顶点对之间最短路径的算法。它通过Bellman-Ford重设边权重来消除负权，然后对每个顶点运行Dijkstra算法，效率很高。
    *   **2.3.1.6 A* 搜索算法 (A* Search Algorithm):**
        (见 1.8.1) 一种启发式搜索算法，常用于游戏中寻路。它在Dijkstra算法基础上增加了一个到终点的估价函数，从而能更智能地朝目标方向搜索。

*   **2.3.2 最小生成树算法 (Minimum Spanning Tree - MST)**
    在一个加权的无向连通图中，寻找一个权值总和最小的子图，该子图连接了所有顶点且不包含环路。
    *   **2.3.2.1 Kruskal算法 (Kruskal's Algorithm):**
        (见 1.4.3) 一种基于边的贪心算法。它将所有边按权重排序，然后从小到大依次选择，只要新加入的边不会形成环路，就将其加入MST。
    *   **2.3.2.2 Prim算法 (Prim's Algorithm):**
        (见 1.4.4) 一种基于顶点的贪心算法。从任意一个顶点开始，逐步将离当前生成树最近的顶点及其对应的边加入，直到覆盖所有顶点。
    *   **2.3.2.3 Borůvka算法 (Borůvka's Algorithm):**
        一种历史悠久且适用于并行计算的MST算法。它在每一轮中，为每个连通分量找到连接到其他分量的权重最小的边，并将这些边加入MST。

*   **2.3.3 网络流算法 (Network Flow Algorithms)**
    研究网络中（如图）的流量问题，例如在一个管网中，从源点到汇点的最大流量是多少。
    *   **2.3.3.1 Ford-Fulkerson算法:**
        一个计算最大流的迭代方法。它反复在残余图中寻找增广路径，并沿着路径增加流量，直到找不到任何增广路径为止。其效率取决于寻找路径的方法。
    *   **2.3.3.2 Edmonds-Karp算法:**
        Ford-Fulkerson算法的一种具体实现，它使用广度优先搜索（BFS）来寻找最短的增广路径。这保证了算法能在多项式时间内结束。
    *   **2.3.3.3 Dinic算法 (Dinitz's Algorithm):**
        一种高效的最大流算法。它首先用BFS构建分层网络，然后用DFS在分层网络中寻找多个增广路径（形成阻塞流），显著提升了效率。
    *   **2.3.3.4 ISAP (Improved Shortest Augmenting Path):**
        Dinic算法的一种优化，通过维护距离标号，避免了每次都重新构建分层网络，在实践中表现优秀。
    *   **2.3.3.5 Push-relabel算法 (推拉重贴标签算法):**
        一种与增广路径思想不同的最大流算法。它维护一个“预流”，通过将“溢出”的节点流量“推送”到邻居节点，并“重贴标签”（更新高度）来将流量推向汇点。
    *   **2.3.3.6 最小费用最大流 (Minimum-cost Maximum-flow):**
        一个更复杂的问题，目标是在满足最大流量（或指定流量）的前提下，使得总的运输费用最小。通常通过在费用图上寻找增广路径来解决。

*   **2.3.4 连通性算法 (Connectivity Algorithms)**
    *   **2.3.4.1 Tarjan算法 (Tarjan's Algorithm for SCCs):**
        一个基于深度优先搜索的强大算法，用于在线性时间内找到有向图中的所有强连通分量（SCC）。
    *   **2.3.4.2 Kosaraju算法 (Kosaraju's Algorithm for SCCs):**
        另一个寻找强连通分量的经典算法。它通过对原图和其转置图分别进行两次深度优先搜索来确定各个强连通分量。
    *   **2.3.4.3 寻找割点和桥 (Finding Cut Vertices and Bridges):**
        基于DFS和Tarjan算法的思想，通过记录节点的发现时间和最低可达祖先时间，可以有效地在一次遍历中找出图中的所有割点（关节点）和桥。

*   **2.3.5 匹配算法 (Matching Algorithms)**
    *   **2.3.5.1 二分图最大匹配 (Bipartite Matching) - 匈牙利算法 (Hungarian Algorithm):**
        用于寻找二分图中最大匹配的经典算法。它通过反复寻找增广路径来增加匹配边的数量，直到无法找到为止。
    *   **2.3.5.2 Hopcroft-Karp算法 (Hopcroft-Karp Algorithm):**
        比匈牙利算法更快的二分图最大匹配算法。它在每一轮中，使用BFS和DFS寻找多条不相交的最短增广路径，从而更快地达到最大匹配。
    *   **2.3.5.3 一般图最大匹配 (Blossom Algorithm / Edmonds' blossom algorithm):**
        用于解决非二分图中的最大匹配问题。其核心思想是通过“开花”（将图中的奇数环收缩成一个伪顶点）来处理奇数环，将其转化为类似二分图的情况。

#### **2.4 字符串算法 (String Algorithms)**

专注于处理和分析字符串序列的算法，在文本编辑、生物信息学、搜索引擎等领域至关重要。

*   **2.4.1 字符串搜索/匹配 (String Matching)**
    在一个较长的文本串中查找一个或多个较短的模式串的出现位置。
    *   **2.4.1.1 朴素/暴力匹配 (Naive String Matching):**
        最直观的方法。将模式串与文本串的每个可能位置逐一比对。简单但效率低下，时间复杂度为O(m*n)。
    *   **2.4.1.2 KMP算法 (Knuth-Morris-Pratt):**
        利用模式串自身的特点，在发生不匹配时，智能地“滑动”模式串，避免了文本串指针的回溯，时间复杂度降至O(n+m)。
    *   **2.4.1.3 Boyer-Moore算法:**
        一种非常高效的字符串匹配算法，其实际表现通常优于KMP。它从后向前匹配，并利用“坏字符规则”和“好后缀规则”进行大步跳跃。
    *   **2.4.1.4 Rabin-Karp算法:**
        一种基于哈希的随机化字符串匹配算法。通过比较模式串和文本子串的哈希值来快速排除不匹配，仅在哈希值相同时才进行逐字符比较。
    *   **2.4.1.5 Aho-Corasick算法:**
        用于同时在一个文本串中查找多个模式串的经典算法。它将所有模式串构建成一个有限状态自动机（Trie树+失败指针），只需一次遍历文本串即可完成匹配。
    *   **2.4.1.6 后缀树/数组相关算法 (Suffix Tree/Array based):**
        构建文本的后缀树或后缀数组后，查找某个模式串是否存在，可以在与模式串长度成正比的时间内完成，非常适合多次查询。

*   **2.4.2 序列比对与最长公共子串/子序列**
    *   **2.4.2.1 最长公共子序列 (LCS):**
        (见 1.3.3) 使用动态规划在两个或多个字符串中寻找最长的公共子序列（不必连续）。
    *   **2.4.2.2 最长公共子串 (Longest Common Substring):**
        寻找两个或多个字符串中最长的连续公共部分。可以使用动态规划或更高效的后缀自动机/后缀树来解决。
    *   **2.4.2.3 Needleman-Wunsch算法:**
        一种在生物信息学中用于进行全局序列比对的动态规划算法。它会尝试比对两个序列的整个长度，并引入空位罚分。
    *   **2.4.2.4 Smith-Waterman算法:**
        与Needleman-Wunsch类似，但用于局部序列比对。它寻找并返回两个序列中相似度最高的片段，而不管序列的其余部分。

*   **2.4.3 字符串数据结构相关**
    *   **2.4.3.1 Trie树 (字典树/前缀树):**
        一种高效的树形数据结构，用于存储和检索字符串集合。常用于搜索引擎的自动补全、词频统计等。每个节点代表一个前缀。
    *   **2.4.3.2 后缀自动机 (Suffix Automaton - SAM):**
        一个功能强大的字符串数据结构，可以接受一个字符串的所有子串。它能在线性时间内构建，并用于解决多种复杂的字符串问题。
    *   **2.4.3.3 Manacher算法:**
        在线性时间内查找一个字符串中最长回文子串的精妙算法。它通过利用回文的对称性，避免了大量重复计算。

#### **2.5 计算几何算法 (Computational Geometry Algorithms)**

研究在几何空间中（通常是二维或三维）的点、线、多边形等几何对象的算法。

*   **2.5.1 凸包算法 (Convex Hull Algorithms)**
    给定平面上的一组点，找到一个最小的凸多边形，使其能包围所有的点。
    *   **2.5.1.1 Graham扫描法 (Graham Scan):**
        一种高效的凸包算法。首先找到一个极点，然后将其余点按极角排序，最后通过一个栈来维护凸包的顶点，时间复杂度为O(n log n)。
    *   **2.5.1.2 Jarvis步进法 (Jarvis March / Gift Wrapping):**
        一种思路简单的凸包算法。从一个极点开始，像“礼品包装”一样，一圈一圈地找到下一个凸包顶点。时间复杂度为O(nh)，其中h是凸包上的顶点数。
    *   **2.5.1.3 Monotone Chain算法 (Andrew's Algorithm):**
        一种与Graham扫描法类似的算法。它将点按x坐标排序，然后分别构造凸包的上半部分和下半部分，实现起来较为简单。
    *   **2.5.1.4 Chan's Algorithm:**
        一种更高级的、结合了Graham扫描法和Jarvis步进法的思想的输出敏感型算法，其时间复杂度为O(n log h)，是理论上最优的算法之一。

*   **2.5.2 相交问题 (Intersection Problems)**
    *   **2.5.2.1 线段相交检测 (Bentley-Ottmann Algorithm):**
        一种扫描线算法，用于高效地找出平面上一组线段所有的交点。它通过维护与扫描线相交的线段顺序，并只检测相邻线段的相交情况。
    *   **2.5.2.2 凸多边形求交:**
        计算两个凸多边形交集的算法。由于凸性，可以设计出高效的线性时间算法来完成。

*   **2.5.3 邻近问题 (Proximity Problems)**
    *   **2.5.3.1 最近点对问题 (Closest Pair Problem):**
        (见 1.2.5) 在一个点集中找到距离最近的两个点。经典的分治算法可以在O(n log n)时间内解决此问题。
    *   **2.5.3.2 Voronoi图 (Voronoi Diagram):**
        对空间中一组点的划分。对于每个点，其对应的Voronoi区域包含了空间中所有离该点比离其他任何点都更近的点。
    *   **2.5.3.3 Delaunay三角剖分 (Delaunay Triangulation):**
        Voronoi图的对偶图。它是一种将点集连接成三角形的剖分，其特性是任何三角形的外接圆内部都不包含点集中的任何其他点。

#### **2.6 数论与代数算法 (Number Theory and Algebraic Algorithms)**

这些算法是解决基于整数、多项式和代数结构的数学问题的基础，尤其在密码学和科学计算中至关重要。

*   **2.6.1 最大公约数 (Greatest Common Divisor - GCD)**
    *   **2.6.1.1 欧几里得算法 (Euclidean Algorithm):**
        一个用于计算两个整数最大公约数的古老而高效的算法。其原理是两个整数的最大公约数等于其中较小的数和两数之差的最大公约数。递归实现非常简洁。
    *   **2.6.1.2 扩展欧几里得算法 (Extended Euclidean Algorithm):**
        欧几里得算法的扩展，除了计算a和b的最大公约数外，还能找到整数x和y，使得 ax + by = gcd(a, b)。这在求解模逆元时非常关键。

*   **2.6.2 素性测试 (Primality Testing)**
    *   **2.6.2.1 试除法 (Trial Division):**
        判断一个数n是否为素数的最简单方法。用从2到√n的所有整数去试着整除n，如果都不能整除，则n是素数。对于大数来说效率极低。
    *   **2.6.2.2 Miller-Rabin素性测试:**
        (见 1.7.3) 一种高效的随机化素性测试算法。它不能100%确定一个数是素数，但能以极高的概率做出正确判断，是目前工程中应用最广泛的素性测试之一。

*   **2.6.3 整数分解 (Integer Factorization)**
    *   **2.6.3.1 Pollard's rho算法:**
        一种用于整数分解的随机化算法。它能比试除法更快地找到一个大合数的一个非平凡因子，尤其对于因子较小的数效果显著。

*   **2.6.4 模运算相关**
    *   **2.6.4.1 快速幂 (Modular Exponentiation / Fast Powering):**
        高效计算 a^b mod m 的算法。通过将指数b进行二进制分解，将幂运算的复杂度从O(b)降低到O(log b)，是RSA等密码学算法的基础。
    *   **2.6.4.2 中国剩余定理 (Chinese Remainder Theorem):**
        用于求解一组同余方程的算法。它给出了一个明确的构造性解法，可以将一个大数的运算，分解到多个小模数的运算上，在密码学和计算机代数中有应用。

*   **2.6.5 多项式与矩阵**
    *   **2.6.5.1 快速傅里叶变换 (FFT) 用于多项式乘法:**
        (见 1.2.7) 两个n次多项式相乘，可以通过FFT在O(n log n)时间内完成。它将多项式从系数表示转换到点值表示，相乘后再用逆FFT转回。

#### **2.7 数据压缩算法 (Data Compression Algorithms)**

旨在减少数据存储空间或网络传输带宽的算法，分为无损压缩和有损压缩两类。

*   **2.7.1 无损压缩 (Lossless Compression)**
    压缩后的数据可以完全恢复成原始数据。
    *   **2.7.1.1 游程编码 (Run-Length Encoding - RLE):**
        一种简单的压缩方法，将连续出现的相同数据（一个“游程”）用一个计数值和该数据值来代替。例如，`AAAAA` 压缩为 `5A`。对包含大量重复数据的图像等文件效果好。
    *   **2.7.1.2 霍夫曼编码 (Huffman Coding):**
        (见 1.4.2) 一种基于字符出现频率的变长编码（VLC）方法。它为高频字符分配短码，为低频字符分配长码，以达到压缩目的。
    *   **2.7.1.3 Lempel-Ziv (LZ) 家族 (LZ77, LZ78, LZW):**
        一类基于字典的压缩算法。它们通过在文本中找到重复的字符串，并用指向该字符串第一次出现位置的引用来替换，是ZIP、GZIP、PNG等格式的核心。
    *   **2.7.1.4 算术编码 (Arithmetic Coding):**
        一种更先进的熵编码方法。它将整个输入消息表示为0和1之间的一个分数，为高概率符号分配更少的比特，通常比霍夫曼编码有更高的压缩率。

*   **2.7.2 有损压缩 (Lossy Compression)**
    在压缩过程中会永久性地丢弃一部分信息，无法完全恢复原始数据，但能获得更高的压缩比。
    *   **2.7.2.1 离散余弦变换 (Discrete Cosine Transform - DCT):**
        JPEG图像压缩的核心。它将图像块从空间域转换到频率域，然后丢弃人眼不敏感的高频分量，从而实现高压缩率。
    *   **2.7.2.2 变换编码 (比如用于MP3的MDCT):**
        类似于DCT，但应用于音频信号。MP3等格式使用改进的离散余弦变换（MDCT）并结合心理声学模型，丢弃人耳听不到或不敏感的音频部分。
    *   **2.7.2.3 向量量化 (Vector Quantization):**
        一种常用于图像和语音压缩的技术。它将大量的输入向量（如图像块）聚类，并用一个小的“码本”中的代表向量来近似，从而实现数据压缩。

#### **2.8 密码学算法 (Cryptography Algorithms)**

用于保护信息安全，实现数据机密性、完整性、身份验证等的算法。

*   **2.8.1 对称密钥加密 (Symmetric-key Cryptography)**
    加密和解密使用相同的密钥。
    *   **2.8.1.1 DES (Data Encryption Standard):**
        曾经的美国联邦标准，一种将64位明文块加密成64位密文的块加密算法。由于其56位的密钥长度较短，现在已被认为不安全。
    *   **2.8.1.2 AES (Advanced Encryption Standard / Rijndael):**
        目前的全球性加密标准。它是一种块加密算法，支持128、192、256位密钥，使用置换-组合网络，提供了高效且强大的安全性。

*   **2.8.2 公钥（非对称密钥）加密 (Public-key Cryptography)**
    使用一对密钥：公钥用于加密，私钥用于解密。
    *   **2.8.2.1 RSA算法:**
        第一个实用的公钥加密算法，其安全性基于大整数分解的困难性。广泛用于数据加密和数字签名。
    *   **2.8.2.2 Diffie-Hellman密钥交换:**
        一种允许双方在不安全的信道上，安全地协商出一个共享密钥的算法。它本身不用于加密，而是用于创建对称加密所需的共享密钥。
    *   **2.8.2.3 椭圆曲线密码学 (Elliptic Curve Cryptography - ECC):**
        一种基于椭圆曲线代数的公钥密码体制。在提供同等级别安全性的前提下，ECC使用比RSA短得多的密钥，因此在移动设备等资源受限环境中特别有优势。

*   **2.8.3 密码学哈希函数 (Cryptographic Hash Functions)**
    将任意长度的数据映射为固定长度的、唯一的“指纹”。
    *   **2.8.3.1 MD5 (Message Digest 5):**
        一个曾被广泛使用的哈希函数，产生128位哈希值。由于已被发现存在严重的碰撞漏洞，现已不应用于安全相关的场合。
    *   **2.8.3.2 SHA家族 (Secure Hash Algorithm):**
        由美国国家安全局设计的一系列哈希函数。SHA-1（160位）已不推荐；SHA-2（如SHA-256）目前仍被广泛使用；SHA-3（Keccak）是最新标准，采用了不同的内部结构。

#### **2.9 机器学习算法 (Machine Learning Algorithms)**

让计算机从数据中“学习”模式和规律，而非通过显式编程来执行任务的算法。

*   **2.9.1 监督学习 (Supervised Learning)**
    从带有标签的训练数据中学习模型。
    *   **2.9.1.1 线性回归/逻辑回归 (Linear/Logistic Regression):**
        基础的预测模型。线性回归用于预测连续值（如房价），逻辑回归用于二元分类问题（如判断邮件是否为垃圾邮件）。
    *   **2.9.1.2 支持向量机 (Support Vector Machine - SVM):**
        一种强大的分类器，其目标是找到一个能以最大“间隔”将不同类别分开的决策边界（超平面）。在处理高维数据和非线性问题时很有效。
    *   **2.9.1.3 K-近邻算法 (k-Nearest Neighbors - k-NN):**
        一种简单直观的非参数算法。它通过查找训练集中与新样本最接近的k个邻居，并根据这些邻居的标签进行投票来预测新样本的类别。
    *   **2.9.1.4 决策树 (Decision Tree):**
        构建一个树状模型，其中每个内部节点表示一个特征测试，每个分支代表测试结果，每个叶节点代表一个类别标签。易于理解和解释。
    *   **2.9.1.5 集成学习 (Ensemble Learning) - 随机森林/梯度提升:**
        通过结合多个“弱”学习器来构建一个强大的“强”学习器。随机森林通过构建多棵决策树并取其平均或投票结果；梯度提升则逐步迭代地构建模型来修正前一个模型的错误。

*   **2.9.2 无监督学习 (Unsupervised Learning)**
    从没有标签的数据中发现隐藏的结构或模式。
    *   **2.9.2.1 K-均值聚类 (K-Means Clustering):**
        一种将数据集划分为K个簇的常用聚类算法。它迭代地将每个数据点分配给最近的簇中心（质心），并更新质心的位置。
    *   **2.9.2.2 DBSCAN (Density-Based Spatial Clustering of Applications with Noise):**
        一种基于密度的聚类算法。它能发现任意形状的簇，并将密度足够低的区域识别为噪声，无需预先指定簇的数量。
    *   **2.9.2.3 主成分分析 (Principal Component Analysis - PCA):**
        一种最常用的降维算法。它通过正交变换将高维数据投影到一组新的低维坐标系（主成分）上，同时最大程度地保留原始数据的方差。

---

### **第三章：按实现方式/特性分类 (Classification by Implementation/Characteristics)**

这个分类维度关注算法的内在结构、行为模式和结果属性，而不是它解决的具体问题。

#### **3.1 递归算法 vs. 迭代算法 (Recursive vs. Iterative)**

*   **3.1.1 递归算法 (Recursive Algorithm):**
    一个算法在其定义或实现中直接或间接地调用自身。它将大问题分解为与原问题相似但规模更小的子问题。如阶乘计算、树的遍历等。
*   **3.1.2 迭代算法 (Iterative Algorithm):**
    使用循环结构（如for, while）来重复执行一系列步骤，直到满足某个终止条件。任何递归算法理论上都可以转化为迭代形式，通常借助栈来模拟递归调用。

#### **3.2 确定性算法 vs. 非确定性/随机化算法 (Deterministic vs. Non-deterministic/Randomized)**

*   **3.2.1 确定性算法 (Deterministic Algorithm):**
    对于任何给定的输入，算法执行的步骤序列和最终输出都是唯一且固定的。绝大多数基础算法，如排序、Dijkstra算法等，都是确定性的。
*   **3.2.2 随机化算法 (Randomized Algorithm):**
    (见 1.7) 在算法执行过程中利用随机性（如随机数生成器）。对于相同的输入，每次运行的路径或结果可能不同。例如，快速排序的随机化版本、蒙特卡洛方法。

#### **3.3 串行 vs. 并行 vs. 分布式 (Serial vs. Parallel vs. Distributed)**

*   **3.3.1 串行算法 (Serial Algorithm):**
    最传统的算法模型，指令按顺序一步一步地在单个处理器上执行。在任意时刻，只有一条指令在被处理。绝大多数基础算法最初都是以串行方式设计的。

*   **3.3.2 并行算法 (Parallel Algorithm):**
    为在多核处理器或多处理器系统上运行而设计。它将一个大任务分解为多个子任务，这些子任务可以同时在不同的处理单元上执行，通常通过共享内存进行通信，以缩短总计算时间。

*   **3.3.3 分布式算法 (Distributed Algorithm):**
    运行在由网络连接的多台独立计算机（节点）上。每个节点只有自己的私有内存，通过消息传递进行通信和协作。例如，Google的MapReduce就是一种处理海量数据的分布式计算框架。

#### **3.4 在线 vs. 离线 (Online vs. Offline)**

*   **3.4.1 离线算法 (Offline Algorithm):**
    在开始执行前，必须获得问题的全部输入数据。这是最常见的算法类型，例如对一个完整的数组进行排序，需要先知道数组的所有元素。

*   **3.4.2 在线算法 (Online Algorithm):**
    按顺序处理输入，且在处理某个输入时，并不知道未来的输入是什么。它必须在信息不完整的情况下做出决策。例如，操作系统的页面置换算法（如LRU）就是一个在线算法。

#### **3.5 原地算法 (In-place Algorithm)**

*   **3.5.1 原地算法 (In-place Algorithm):**
    指一个算法基本上不需要借助额外的存储空间来完成计算，其空间复杂度为O(1)。换句话说，它主要在输入数据本身所占用的存储空间内进行操作。例如，堆排序是原地算法，而归并排序通常不是。

#### **3.6 稳定算法 (Stable Algorithm)**

*   **3.6.1 稳定算法 (Stable Algorithm) - 特指排序:**
    一个排序算法是稳定的，如果两个具有相等键值的元素在排序后，其相对顺序与排序前保持不变。稳定性在需要根据多个键进行排序时非常重要。例如，归并排序是稳定的，而快速排序和堆排序是不稳定的。

---

### **第四章：按计算模型/前沿领域分类 (Classification by Computational Model/Frontier)**

这一分类着眼于驱动算法设计的底层计算范式，其中一些代表了计算机科学的最前沿。

#### **4.1 量子算法 (Quantum Algorithms)**

为在量子计算机上运行而设计的算法，利用量子力学现象（如叠加态和纠缠）来解决特定问题，其速度可能远超传统计算机。

*   **4.1.1 Shor算法 (Shor's Algorithm):**
    一种革命性的量子算法，可以在多项式时间内分解大整数。它的存在理论上对当前广泛使用的RSA公钥密码体系构成了颠覆性威胁。

*   **4.1.2 Grover算法 (Grover's Algorithm):**
    一种量子搜索算法，对于一个无序的、包含N个条目的数据库，它能在O(√N)时间内找到目标条目，相比传统算法的O(N)实现了二次加速。

#### **4.2 流式算法 (Streaming Algorithms / Data Stream Algorithms)**

用于处理持续、高速、海量的数据流（如网络流量、传感器数据），这些数据因其巨大而无法被完全存储。

*   **4.2.1 流式算法 (Streaming Algorithm):**
    这类算法通常只能对数据进行一次（或少数几次）扫描，并且必须使用远小于数据总量的内存空间。它们通常提供的是近似解而非精确解。

*   **4.2.2 Count-Min Sketch算法:**
    一种流式算法，用于估算数据流中各项的出现频率。它使用一个二维数组（Sketch）和多个哈希函数，以极小的空间开销提供高精度的频率近似值。

*   **4.2.3 HyperLogLog算法:**
    用于在数据流中估算不同元素（基数）数量的概率性算法。它能用惊人小的内存（如1.5 KB）估算出高达数十亿级别的基数，误差率可控。

#### **4.3 生物启发式计算 (Bio-inspired Computing)**

这一类别泛指从自然界（尤其是生物系统）的行为、结构和过程中获得灵感而设计的算法，它们通常属于启发式算法的范畴（见1.8）。

*   **4.3.1 遗传算法 (Genetic Algorithm):**
    (见 1.8.3) 模拟达尔文的自然选择和遗传学原理，通过“适者生存”的迭代过程（选择、交叉、变异）来搜索最优解。

*   **4.3.2 蚁群优化 (Ant Colony Optimization):**
    (见 1.8.4) 模仿蚂蚁寻找食物时通过信息素进行交流的行为，用于寻找组合优化问题（如TSP）的优化路径。

*   **4.3.3 粒子群优化 (Particle Swarm Optimization - PSO):**
    (见 1.8.5) 模拟鸟群或鱼群的集体行为。每个“粒子”代表一个潜在解，通过跟随自身和群体的“最优”经验来在解空间中进行搜索。

*   **4.3.4 模拟退火 (Simulated Annealing):**
    (见 1.8.2) 来源于冶金学中固体退火过程的启发。它允许算法在搜索过程中以一定概率接受一个“更差”的解，从而有机会跳出局部最优，寻找全局最优。

---

### **文档结论**

至此，这份算法分类大全的构建工作已全部完成。我们从四个主要的维度对算法进行了系统性的梳理和介绍：

1.  **按设计范式/策略分类：** 揭示了算法设计的核心思想，如分治、动态规划、贪心等。
2.  **按问题领域/应用分类：** 聚焦于算法的实际用途，涵盖了排序、搜索、图论、字符串处理、机器学习等众多领域。
3.  **按实现方式/特性分类：** 关注算法的内在属性，如递归/迭代、确定性/随机性、空间占用等。
4.  **按计算模型/前沿领域分类：** 展望了算法的未来，介绍了量子计算、流式计算等新兴范式。
