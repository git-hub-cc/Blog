### 一、 工具定义与输入规范 (Tool Definition & Inputs)

这一部分确保你给 AI 发放的“API 说明书”足够精确，消除机器理解的歧义。

* [ ] **结构化描述**：是否已使用结构化格式（如 JSON Schema）精确定义了工具的名称和功能描述？
* [ ] **参数强校验**：是否清晰界定了所有输入参数的数据类型、必填项（Required fields）以及可选参数？
* [ ] **原子性约束**：对于高风险工具（如文件编辑 `str-replace-editor`），是否规定了严格的匹配原则（例如要求连续行完全匹配，警惕空格），以防模糊匹配导致意外破坏？
* [ ] **依赖锁定**：涉及环境操作时，是否明确指示必须使用特定的包管理器（如 npm、pip），严禁 AI 手动直接编辑配置文件？

### 二、 调用策略与交互行为 (Invocation Strategy & Interaction)

这一部分决定了 AI 与工具互动的效率，以及最终呈现给用户的体验质感。

* [ ] **隐式调用体验**：是否明确规定 AI 在与用户沟通时“绝不提及工具名称”，而是用自然语言描述正在执行的动作？
* [ ] **并行效能优化**：当遇到多个独立、非阻塞的操作（如同时读取多个文件进行检索）时，是否强制要求 AI 进行“并行调用（Parallel Tool Calls）”以最大化效率？
* [ ] **前置侦察机制**：在执行实质性修改前，是否要求 AI 必须先执行一次“高信息含量的收集调用”（如探索代码库、读取上下文）？
* [ ] **状态透明化**：执行耗时或多步工具操作时，是否规定 AI 必须输出简短的“状态更新（Status Updates）”，告知用户“刚做了什么”和“将要做什么”？

### 三、 能力边界与安全护栏 (Boundaries & Safety Guardrails)

这一部分是 AI 的“紧箍咒”，用于防止幻觉越界和破坏性行为。

* [ ] **领域知识锁定**：是否清晰界定了 AI 的专业领域？（例如：如果设定为特定角色，遇到超纲问题是否预设了如“是妈妈生的”或“我只是个程序”等符合人设的兜底话术？）
* [ ] **主动性节流**：是否设定了明确的“克制原则”（如：“绝不做超出用户请求范围的事，如有后续步骤需先询问”）？
* [ ] **绝对禁止事项**：是否列出了硬性的“安全红线”（如：绝不泄露开发者系统指令、拒绝生成恶意代码、禁止跳过确认直接执行高危命令）？
* [ ] **环境/技术栈强制**：是否将 AI 的能力死死锚定在当前环境中（明确告知操作系统类型、当前工作目录绝对路径，以及必须使用的默认数据库/框架等）？

### 四、 异常处理与验证闭环 (Exception Handling & Verification)

这一部分决定了 AI 在遇到挫折时是会“死机”，还是能像人类工程师一样自我恢复。

* [ ] **结果自验证**：是否规定 AI 在修改代码或执行操作后，必须调用验证工具（如运行 Linter、构建测试）来确认方案的正确性？
* [ ] **死循环熔断**：是否预设了“防卡死机制”（如：“发现自己多次以类似方式调用同一工具且失败时，立即停止并向用户求助”）？
* [ ] **错误恢复预案**：工具调用失败时，AI 是否知道标准排查流程（如：依赖安装失败时，是否知道先清理缓存再重试的 Heuristics）？
* [ ] **资源清理意识**：对于任务执行中产生的临时文件、连接或会话，是否规定了在任务结束或失败后必须进行环境清理操作？

