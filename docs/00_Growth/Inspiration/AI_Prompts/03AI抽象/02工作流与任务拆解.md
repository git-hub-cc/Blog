### 支柱二：“蓝图先行”与原子化 SOP (工作流与任务拆解) 检查表

这个阶段的核心目标是：**拒绝“一键生成”的黑盒冒险，将复杂的宏大目标转化为 AI 可理解、可执行且人类可控的流水线。**

#### 1. 意图澄清与缺口识别 (Intent & Information Gaps)

* **真实意图对齐：** 提示词中是否强制要求 AI 在行动前，先复述并向你确认它的理解？（例如：让 AI 明确回答这次任务是为了重构现有模块，还是为了快速产出一个 MVP 验证核心概念）
* **信息盲区探查：** 是否规定了 AI 必须主动进行“依赖检查”？（例如：在开始编码前，主动询问是否缺少必要的 API 密钥、具体的接口文档或环境变量配置）
* **上下文充足度：** 提供给 AI 的背景信息是否经过了裁剪？（例如：对于大型项目，是否只提供了相关的局部目录结构或核心逻辑代码，避免上下文窗口过载导致注意力失焦）

#### 2. 蓝图构建与策略前置 (Blueprint & Strategy First)

* **架构与代码分离：** 是否设立了严格的“防冲动”护栏，禁止 AI 在第一步直接生成代码？（必须先输出纯文本的技术实现蓝图、数据模型或目录结构规划）
* **技术路线确认：** 蓝图中是否包含了明确的技术选型和规范依据？（例如：明确要求在评估移动端跨平台框架方案时，先列出优缺点和社区生态对比，选定后再深入细节）
* **风险预判与备用预案 (Plan B)：** 是否要求 AI 提前评估了潜在的技术卡点？（例如：如果首选的网络请求库存在兼容性问题，是否有替代方案）

#### 3. 原子化任务拆解 (Atomic Task Decomposition)

* **最小可执行单元：** 拆分出的任务是否足够“原子化”？（标准：目标单一、无需中途大幅切换上下文、可一次性完成。例如“编写 `utils.js` 中的日期格式化函数”，而不是模糊的“完成前端页面UI”）
* **依赖关系逻辑：** 任务列表是否体现了严格的前置与后置顺序？（例如：在让 AI 写任何前端组件之前，是否已经强制它先完成了后端 API 契约和 Mock 数据的定义）
* **并行化可能性：** 是否指导 AI 找出了可以同时执行的独立任务以提高效率？（例如：同时检索或读取多个不相关的配置文件）

#### 4. 执行控制与验证闭环 (Execution & Verification)

* **可验证的里程碑：** 每个原子任务是否有客观的“完成验收标准”？（例如：修改完配置文件后，必须确保特定的 Docker 容器能够成功启动并输出预期的运行日志）
* **过程状态反馈：** 是否要求 AI 在执行关键步骤时进行状态汇报？（例如：使用待办列表格式打钩，或在输出代码前先用一句话说明当前进度）
* **错误熔断与恢复机制：** 是否预设了 AI 陷入死循环或反复报错时的“停机求助”指令？（例如：规定“如果同一段代码修改后连续两次测试失败，停止尝试并向我解释当前的错误思路”）

